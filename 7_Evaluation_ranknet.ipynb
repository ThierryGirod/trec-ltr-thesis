{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from ltr.data import CorpusApi, Config\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = CorpusApi.getValidationQueriesAsDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationMap = {}\n",
    "\n",
    "with open('data/validation/docv2_trec2020_qrels.txt', 'r') as txt:\n",
    "    txtReader = csv.reader(txt, delimiter=' ')\n",
    "    for line in txtReader:\n",
    "        queryMap = evaluationMap.get(line[0], {})\n",
    "        forwardIndexList = queryMap.get(line[3],[])\n",
    "        forwardIndexList.append(line[2])\n",
    "        queryMap[line[3]] = forwardIndexList\n",
    "        reverseIndexMap = queryMap.get('reverse', {})\n",
    "        reverseIndexMap[line[2]] = line[3]\n",
    "        queryMap['reverse'] = reverseIndexMap\n",
    "        \n",
    "        evaluationMap[line[0]] = queryMap\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def reciprocalRank(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    rank = 1\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    for docId in evalList:\n",
    "        v = lookupMap.get(docId)\n",
    "        if v is None or int(v) == 0:\n",
    "            rank += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return 1/rank if rank <= 100 else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePrecision(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    foundDocs = 0\n",
    "    \n",
    "    sum = 0\n",
    "    \n",
    "    for i, docId in enumerate(evalList):\n",
    "        v = lookupMap.get(docId)\n",
    "        if v is not None and int(v) != 0:\n",
    "            foundDocs += 1\n",
    "            sum += (foundDocs / (i + 1))\n",
    "            \n",
    "    \n",
    "    return sum / len(evalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def normalizedDiscountedCumulativeGain(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    # create gain list\n",
    "    gainList = [int(lookupMap.get(docId, 0)) for docId in evalList]\n",
    "    #print(gainList)\n",
    "    \n",
    "    # create optimal gain list\n",
    "    keys = list(evaluationMap[queryId].keys()).copy()\n",
    "    \n",
    "    if 'reverse' in keys:\n",
    "        keys.remove('reverse')\n",
    "    \n",
    "    if 'rr' in keys:\n",
    "        keys.remove('rr')\n",
    "    \n",
    "    if 'ap' in keys:\n",
    "        keys.remove('ap')\n",
    "    \n",
    "    if 'ndcg' in keys:\n",
    "        keys.remove('ndcg')\n",
    "    \n",
    "    if 'ncg' in keys:\n",
    "        keys.remove('ncg')\n",
    "    \n",
    "    keys = [int(idx) for idx in keys]\n",
    "    \n",
    "    optimalGainList = []\n",
    "    for key in sorted(keys, reverse=True):\n",
    "        gains = [key for value in range(0,len(evaluationMap[queryId][str(key)]))]\n",
    "        optimalGainList.extend(gains)\n",
    "    \n",
    "    optimalGainList = optimalGainList[:len(evalList)]\n",
    "    \n",
    "    dcg = 0\n",
    "    \n",
    "    for i in range(0, len(gainList)):\n",
    "        dcg += gainList[i] / math.log2(i + 2)\n",
    "        \n",
    "    idcg = 0\n",
    "    for i in range(0, len(optimalGainList)):\n",
    "        idcg += optimalGainList[i] / math.log2(i + 2)\n",
    "        \n",
    "    return dcg / idcg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalizedCumulativeGain(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    # create gain list\n",
    "    gainList = [int(lookupMap.get(docId, 0)) for docId in evalList]\n",
    "    #print(gainList)\n",
    "    \n",
    "    # create optimal gain list\n",
    "    keys = list(evaluationMap[queryId].keys()).copy()\n",
    "    \n",
    "    if 'reverse' in keys:\n",
    "        keys.remove('reverse')\n",
    "    \n",
    "    if 'rr' in keys:\n",
    "        keys.remove('rr')\n",
    "    \n",
    "    if 'ap' in keys:\n",
    "        keys.remove('ap')\n",
    "    \n",
    "    if 'ndcg' in keys:\n",
    "        keys.remove('ndcg')\n",
    "    \n",
    "    if 'ncg' in keys:\n",
    "        keys.remove('ncg')\n",
    "    \n",
    "    keys = [int(idx) for idx in keys]\n",
    "    \n",
    "    optimalGainList = []\n",
    "    for key in sorted(keys, reverse=True):\n",
    "        gains = [key for value in range(0,len(evaluationMap[queryId][str(key)]))]\n",
    "        optimalGainList.extend(gains)\n",
    "    \n",
    "    optimalGainList = optimalGainList[:len(evalList)]\n",
    "    \n",
    "\n",
    "    return sum(gainList) / sum(optimalGainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: 0\n",
      "NDCG: 0.0\n",
      "NCG: 0.0\n",
      "AP: 0.0\n",
      "processed 0/45 42255 query: average salary for dental hygienist in nebraska\n",
      "RR: 0.16666666666666666\n",
      "NDCG: 0.07839826897867533\n",
      "NCG: 0.345679012345679\n",
      "AP: 0.024693591288073753\n",
      "processed 1/45 47210 query: average wedding dress alteration cost\n",
      "RR: 1.0\n",
      "NDCG: 0.08069862424496003\n",
      "NCG: 0.12162162162162163\n",
      "AP: 0.014819723049729092\n",
      "processed 2/45 67316 query: can fever cause miscarriage early pregnancy\n",
      "RR: 0.3333333333333333\n",
      "NDCG: 0.3086147415907597\n",
      "NCG: 0.07894736842105263\n",
      "AP: 0.014083333333333331\n",
      "processed 3/45 135802 query: definition of laudable\n",
      "RR: 0.1\n",
      "NDCG: 0.037665676876396506\n",
      "NCG: 0.25\n",
      "AP: 0.0031543016370602583\n",
      "processed 4/45 156498 query: do google docs auto save\n",
      "RR: 0.3333333333333333\n",
      "NDCG: 0.09650766274495248\n",
      "NCG: 0.24299065420560748\n",
      "AP: 0.027264958362455235\n",
      "processed 5/45 169208 query: does mississippi have an income tax\n",
      "RR: 1.0\n",
      "NDCG: 0.22009176629808014\n",
      "NCG: 0.08\n",
      "AP: 0.011332127787823991\n",
      "processed 6/45 174463 query: dog day afternoon meaning\n",
      "RR: 1.0\n",
      "NDCG: 0.17828412959034637\n",
      "NCG: 0.18055555555555555\n",
      "AP: 0.019380571137153767\n",
      "processed 7/45 258062 query: how long does it take to remove wisdom tooth\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for i, key in enumerate(list(evaluationMap.keys())[:]):\n",
    "    try:\n",
    "        # get query\n",
    "        query = queries[key]\n",
    "        \n",
    "        \n",
    "        # prepare for ltr\n",
    "        queryTokens = word_tokenize(query)\n",
    "        tcqtValues = ', '.join([f\"if(termfreq(title,'{t}'),1,0)\" for t in queryTokens])\n",
    "        hcqtValues = ', '.join([f\"if(termfreq(headings,'{t}'),1,0)\" for t in queryTokens])\n",
    "        bcqtValues = ', '.join([f\"if(termfreq(body,'{t}'),1,0)\" for t in queryTokens])\n",
    "        dcqtValues = ', '.join([f\"if(termfreq(_text_,'{t}'),1,0)\" for t in queryTokens])\n",
    "        ttfValues = ', '.join([f\"tf(title,'{t}')\" for t in queryTokens])\n",
    "        htfValues = ', '.join([f\"tf(headings,'{t}')\" for t in queryTokens])\n",
    "        btfValues = ', '.join([f\"tf(body,'{t}')\" for t in queryTokens])\n",
    "        dtfValues = ', '.join([f\"tf(_text_,'{t}')\" for t in queryTokens])\n",
    "        tidfValues = ', '.join([f\"idf(title,'{t}')\" for t in queryTokens])\n",
    "        hidfValues = ', '.join([f\"idf(headings,'{t}')\" for t in queryTokens])\n",
    "        bidfValues = ', '.join([f\"idf(body,'{t}')\" for t in queryTokens])\n",
    "        didfValues = ', '.join([f\"idf(_text_,'{t}')\" for t in queryTokens])\n",
    "        ttfidfValues = ', '.join([f\"product(tf(title,'{t}'),idf(title,'{t}'))\" for t in queryTokens])\n",
    "        htfidfValues = ', '.join([f\"product(tf(headings,'{t}'),idf(headings,'{t}'))\" for t in queryTokens])\n",
    "        btfidfValues = ', '.join([f\"product(tf(body,'{t}'),idf(body,'{t}'))\" for t in queryTokens])\n",
    "        dtfidfValues = ', '.join([f\"product(tf(_text_,'{t}'),idf(_text_,'{t}'))\" for t in queryTokens])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # get result from solr\n",
    "        request = {\n",
    "            \"fields\": \"id\",\n",
    "            \"limit\": 100,\n",
    "            \"params\": {\n",
    "                \"rq\": \"{!ltr reRankDocs=500 \" + \n",
    "                    f\"\"\"\n",
    "                  efi.keywords=\\\"{query}\\\" \n",
    "                  efi.tcqt_values=\\\"  {tcqtValues}\n",
    "                  \\\" \n",
    "                  efi.hcqt_values=\\\"  {hcqtValues}\n",
    "                  \\\"\n",
    "                  efi.bcqt_values=\\\"  {bcqtValues}\n",
    "                  \\\"\n",
    "                  efi.dcqt_values=\\\"  {dcqtValues}\n",
    "                  \\\"\n",
    "                  efi.query_terms_length={len(queryTokens)}\n",
    "                  efi.ttf_values=\\\"  {ttfValues}\n",
    "                  \\\" \n",
    "                  efi.htf_values=\\\"  {htfValues}\n",
    "                  \\\" \n",
    "                  efi.btf_values=\\\"  {btfValues}\n",
    "                  \\\" \n",
    "                  efi.dtf_values=\\\"  {dtfValues}\n",
    "                  \\\" \n",
    "                  efi.tidf_values=\\\"  {tidfValues}\n",
    "                  \\\" \n",
    "                  efi.hidf_values=\\\"  {hidfValues}\n",
    "                  \\\" \n",
    "                  efi.bidf_values=\\\"  {bidfValues}\n",
    "                  \\\" \n",
    "                  efi.didf_values=\\\"  {didfValues}\n",
    "                  \\\" \n",
    "                  efi.ttfidf_values=\\\"  {ttfidfValues}\n",
    "                  \\\" \n",
    "                  efi.htfidf_values=\\\"  {htfidfValues}\n",
    "                  \\\" \n",
    "                  efi.btfidf_values=\\\"  {btfidfValues}\n",
    "                  \\\" \n",
    "                  efi.dtfidf_values=\\\"  {dtfidfValues}\n",
    "                  \\\" \n",
    "          \"\"\"\n",
    "                +\"model=thesis-ranknet }\",\n",
    "                \"qf\": \"title headings body\",\n",
    "                \"defType\": \"dismax\",\n",
    "                \"q\": query\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if key == ' 10000':\n",
    "            print(json.dumps(request, indent=2))\n",
    "        \n",
    "        response = requests.post(f'http://localhost:8983/solr/thesis-ltr/select', json=request)\n",
    "        \n",
    "        queryResult = [doc['id'] for doc in response.json()[\"response\"][\"docs\"]]\n",
    "        \n",
    "        \n",
    "        # calculate metrics\n",
    "        # Reciprocal Rank\n",
    "        rr = reciprocalRank(key, queryResult)\n",
    "        evaluationMap[key]['rr'] = rr\n",
    "        print(f'RR: {rr}')\n",
    "        # Normalized Discounted Cumulative Gains (NDCG)\n",
    "        ndcg = normalizedDiscountedCumulativeGain(key, queryResult[:10])\n",
    "        evaluationMap[key]['ndcg'] = ndcg\n",
    "        print(f'NDCG: {ndcg}')\n",
    "        # Normalized Cumulative Gains (NCG)\n",
    "        ncg = normalizedCumulativeGain(key, queryResult)\n",
    "        evaluationMap[key]['ncg'] = ncg\n",
    "        print(f'NCG: {ncg}')\n",
    "        # Average Precision (AP)\n",
    "        ap = averagePrecision(key, queryResult)\n",
    "        evaluationMap[key]['ap'] = ap\n",
    "        print(f'AP: {ap}')\n",
    "        \n",
    "        print(f'processed {i}/{len(list(evaluationMap.keys())[:])} {key} query: {query}')\n",
    "    except KeyError as err:\n",
    "        # ignore the queries that are not in the validation queries list\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rr = 0\n",
    "bm25_ap = 0\n",
    "bm25_ndcg = 0\n",
    "bm25_ncg = 0\n",
    "counter = 0\n",
    "for key in list(evaluationMap.keys()):\n",
    "    try:\n",
    "        bm25_rr += evaluationMap[key]['rr']\n",
    "        bm25_ap += evaluationMap[key]['ap']\n",
    "        bm25_ndcg += evaluationMap[key]['ndcg']\n",
    "        bm25_ncg += evaluationMap[key]['ncg']\n",
    "        counter += 1\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rr = bm25_rr/counter\n",
    "bm25_ap = bm25_ap/counter\n",
    "bm25_ndcg = bm25_ndcg/counter\n",
    "bm25_ncg = bm25_ncg/counter\n",
    "\n",
    "print(f'exp_bm25: rr:{bm25_rr} / ap:{bm25_ap} / ndcg@10:{bm25_ndcg} / ncg:{bm25_ncg}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
