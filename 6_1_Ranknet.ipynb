{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow matplotlib scikit-learn pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations, losses, Model, Input\n",
    "from tensorflow.nn import leaky_relu\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tensorflow.keras.utils import plot_model, Progbar\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "  # model architecture\n",
    "  class RankNet(Model):\n",
    "      def __init__(self):\n",
    "          super().__init__()\n",
    "          self.dense = [layers.Dense(16, activation=leaky_relu), layers.Dense(8, activation=leaky_relu)]\n",
    "          self.o = layers.Dense(1, activation='linear')\n",
    "          self.oi_minus_oj = layers.Subtract()\n",
    "      \n",
    "      def call(self, inputs):\n",
    "          xi, xj = inputs\n",
    "          densei = self.dense[0](xi)\n",
    "          densej = self.dense[0](xj)\n",
    "          for dense in self.dense[1:]:\n",
    "              densei = dense(densei)\n",
    "              densej = dense(densej)\n",
    "          oi = self.o(densei)\n",
    "          oj= self.o(densej)\n",
    "          oij = self.oi_minus_oj([oi, oj])\n",
    "          output = layers.Activation('sigmoid')(oij)\n",
    "          return output\n",
    "      \n",
    "      def build_graph(self):\n",
    "          x = [Input(shape=(10)), Input(shape=(10))]\n",
    "          return Model(inputs=x, outputs=self.call(x))\n",
    "\n",
    "# visualize model architecture\n",
    "plot_model(RankNet().build_graph(), show_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "def getJudgmentsBatchFileByFile():\n",
    "    \"\"\"\n",
    "    Returns a generator function that returns all the judgment batches files from the directory\n",
    "    \"\"\"\n",
    "    files = []\n",
    "   \n",
    "    files = [join('./loggedFeatures', file) for file in listdir('./loggedFeatures') if isfile(join('./loggedFeatures', file))]\n",
    "    for file in files:\n",
    "        yield file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "judgments = []\n",
    "for file in getJudgmentsBatchFileByFile():\n",
    "  with open(file,'r') as f:\n",
    "    reader = csv.reader(f, delimiter=' ')\n",
    "    for row in reader:\n",
    "      data = []\n",
    "      for element in row:\n",
    "        data.append(element.replace(',', ''))\n",
    "      judgments.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgments.sort(key = lambda judgments: judgments[1])\n",
    "print(judgments[0])\n",
    "print(judgments[1])\n",
    "print(judgments[2])\n",
    "print(judgments[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in judgments:\n",
    "  del j[2]\n",
    "\n",
    "print(judgments[0])\n",
    "print(judgments[1])\n",
    "print(judgments[2])\n",
    "print(judgments[3])\n",
    "print(judgments[4])\n",
    "print(judgments[5])\n",
    "print(judgments[6])\n",
    "print(judgments[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pairs\n",
    "xi = []\n",
    "xj = []\n",
    "pij = []\n",
    "judgmentPairs = []\n",
    "\n",
    "for i in range(1, len(judgments), 2):\n",
    "  judgmentPairs.append([judgments[i - 1], judgments[i]])\n",
    "  xi.append(judgments[i - 1][2:])\n",
    "  xj.append(judgments[i][2:])\n",
    "  if judgments[i-1][0] == judgments[i][0]:\n",
    "    _pij = 0.5\n",
    "  elif judgments[i-1][0] > judgments[i][0]:\n",
    "    _pij = 1\n",
    "  else: \n",
    "    _pij = 0\n",
    "  pij.append(_pij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = np.array(xi, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xj = np.array(xj, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pij = np.array(pij, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xi_train, xi_test, xj_train, xj_test, pij_train, pij_test = train_test_split(\n",
    "    xi, xj, pij, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"training/ranknet.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "# train model using compile and fit\n",
    "with tf.device('/device:GPU:0'):\n",
    "  ranknet = RankNet()\n",
    "  ranknet.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "  history = ranknet.fit([xi_train, xj_train], pij_train, epochs=50, batch_size=1, validation_data=([xi_test, xj_test], pij_test), callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting loss\n",
    "def plot_metrics(train_metric, val_metric=None, metric_name=None, title=None, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    if val_metric is not None: plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plot loss history\n",
    "plot_metrics(history.history['loss'], history.history['val_loss'], \"Loss\", \"Loss\", ylim=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
