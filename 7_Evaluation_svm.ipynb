{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from ltr.data import CorpusApi, Config\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = CorpusApi.getValidationQueriesAsDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationMap = {}\n",
    "\n",
    "with open('data/validation/docv2_trec2020_qrels.txt', 'r') as txt:\n",
    "    txtReader = csv.reader(txt, delimiter=' ')\n",
    "    for line in txtReader:\n",
    "        queryMap = evaluationMap.get(line[0], {})\n",
    "        forwardIndexList = queryMap.get(line[3],[])\n",
    "        forwardIndexList.append(line[2])\n",
    "        queryMap[line[3]] = forwardIndexList\n",
    "        reverseIndexMap = queryMap.get('reverse', {})\n",
    "        reverseIndexMap[line[2]] = line[3]\n",
    "        queryMap['reverse'] = reverseIndexMap\n",
    "        \n",
    "        evaluationMap[line[0]] = queryMap\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def reciprocalRank(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    rank = 1\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    for docId in evalList:\n",
    "        v = lookupMap.get(docId)\n",
    "        if v is None or int(v) == 0:\n",
    "            rank += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return 1/rank if rank <= 100 else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePrecision(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    foundDocs = 0\n",
    "    \n",
    "    sum = 0\n",
    "    \n",
    "    for i, docId in enumerate(evalList):\n",
    "        v = lookupMap.get(docId)\n",
    "        if v is not None and int(v) != 0:\n",
    "            foundDocs += 1\n",
    "            sum += (foundDocs / (i + 1))\n",
    "            \n",
    "    \n",
    "    return sum / len(evalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def normalizedDiscountedCumulativeGain(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    # create gain list\n",
    "    gainList = [int(lookupMap.get(docId, 0)) for docId in evalList]\n",
    "    #print(gainList)\n",
    "    \n",
    "    # create optimal gain list\n",
    "    keys = list(evaluationMap[queryId].keys()).copy()\n",
    "    \n",
    "    if 'reverse' in keys:\n",
    "        keys.remove('reverse')\n",
    "    \n",
    "    if 'rr' in keys:\n",
    "        keys.remove('rr')\n",
    "    \n",
    "    if 'ap' in keys:\n",
    "        keys.remove('ap')\n",
    "    \n",
    "    if 'ndcg' in keys:\n",
    "        keys.remove('ndcg')\n",
    "    \n",
    "    if 'ncg' in keys:\n",
    "        keys.remove('ncg')\n",
    "    \n",
    "    keys = [int(idx) for idx in keys]\n",
    "    \n",
    "    optimalGainList = []\n",
    "    for key in sorted(keys, reverse=True):\n",
    "        gains = [key for value in range(0,len(evaluationMap[queryId][str(key)]))]\n",
    "        optimalGainList.extend(gains)\n",
    "    \n",
    "    optimalGainList = optimalGainList[:len(evalList)]\n",
    "    \n",
    "    dcg = 0\n",
    "    \n",
    "    for i in range(0, len(gainList)):\n",
    "        dcg += gainList[i] / math.log2(i + 2)\n",
    "        \n",
    "    idcg = 0\n",
    "    for i in range(0, len(optimalGainList)):\n",
    "        idcg += optimalGainList[i] / math.log2(i + 2)\n",
    "        \n",
    "    return dcg / idcg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalizedCumulativeGain(queryId: int, evalList: List) -> float:\n",
    "    \n",
    "    lookupMap = evaluationMap[queryId].get('reverse')\n",
    "    \n",
    "    # create gain list\n",
    "    gainList = [int(lookupMap.get(docId, 0)) for docId in evalList]\n",
    "    #print(gainList)\n",
    "    \n",
    "    # create optimal gain list\n",
    "    keys = list(evaluationMap[queryId].keys()).copy()\n",
    "    \n",
    "    if 'reverse' in keys:\n",
    "        keys.remove('reverse')\n",
    "    \n",
    "    if 'rr' in keys:\n",
    "        keys.remove('rr')\n",
    "    \n",
    "    if 'ap' in keys:\n",
    "        keys.remove('ap')\n",
    "    \n",
    "    if 'ndcg' in keys:\n",
    "        keys.remove('ndcg')\n",
    "    \n",
    "    if 'ncg' in keys:\n",
    "        keys.remove('ncg')\n",
    "    \n",
    "    keys = [int(idx) for idx in keys]\n",
    "    \n",
    "    optimalGainList = []\n",
    "    for key in sorted(keys, reverse=True):\n",
    "        gains = [key for value in range(0,len(evaluationMap[queryId][str(key)]))]\n",
    "        optimalGainList.extend(gains)\n",
    "    \n",
    "    optimalGainList = optimalGainList[:len(evalList)]\n",
    "    \n",
    "\n",
    "    return sum(gainList) / sum(optimalGainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for i, key in enumerate(list(evaluationMap.keys())[:]):\n",
    "    try:\n",
    "        # get query\n",
    "        query = queries[key]\n",
    "        \n",
    "        \n",
    "        # prepare for ltr\n",
    "        queryTokens = word_tokenize(query)\n",
    "        tcqtValues = ', '.join([f\"if(termfreq(title_classic,'{t}'),1,0)\" for t in queryTokens])\n",
    "        hcqtValues = ', '.join([f\"if(termfreq(headings_classic,'{t}'),1,0)\" for t in queryTokens])\n",
    "        bcqtValues = ', '.join([f\"if(termfreq(body_classic,'{t}'),1,0)\" for t in queryTokens])\n",
    "        dcqtValues = ', '.join([f\"if(termfreq(_copy_all_classic_,'{t}'),1,0)\" for t in queryTokens])\n",
    "        ttfValues = ', '.join([f\"tf(title_classic,'{t}')\" for t in queryTokens])\n",
    "        htfValues = ', '.join([f\"tf(headings_classic,'{t}')\" for t in queryTokens])\n",
    "        btfValues = ', '.join([f\"tf(body_classic,'{t}')\" for t in queryTokens])\n",
    "        dtfValues = ', '.join([f\"tf(_copy_all_classic_,'{t}')\" for t in queryTokens])\n",
    "        tidfValues = ', '.join([f\"idf(title_classic,'{t}')\" for t in queryTokens])\n",
    "        hidfValues = ', '.join([f\"idf(headings_classic,'{t}')\" for t in queryTokens])\n",
    "        bidfValues = ', '.join([f\"idf(body_classic,'{t}')\" for t in queryTokens])\n",
    "        didfValues = ', '.join([f\"idf(_copy_all_classic_,'{t}')\" for t in queryTokens])\n",
    "        ttfidfValues = ', '.join([f\"product(tf(title_classic,'{t}'),idf(title_classic,'{t}'))\" for t in queryTokens])\n",
    "        htfidfValues = ', '.join([f\"product(tf(headings_classic,'{t}'),idf(headings_classic,'{t}'))\" for t in queryTokens])\n",
    "        btfidfValues = ', '.join([f\"product(tf(body_classic,'{t}'),idf(body_classic,'{t}'))\" for t in queryTokens])\n",
    "        dtfidfValues = ', '.join([f\"product(tf(_copy_all_classic_,'{t}'),idf(_copy_all_classic_,'{t}'))\" for t in queryTokens])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # get result from solr\n",
    "        request = {\n",
    "            \"fields\": \"id\",\n",
    "            #\"limit\": 100,\n",
    "            \"params\": {\n",
    "                \"rq\": \"{!ltr reRankDocs=500 \" + \n",
    "                    f\"\"\"\n",
    "                  efi.keywords=\\\"{query}\\\" \n",
    "                  efi.tcqt_values=\\\"  {tcqtValues}\n",
    "                  \\\" \n",
    "                  efi.hcqt_values=\\\"  {hcqtValues}\n",
    "                  \\\"\n",
    "                  efi.bcqt_values=\\\"  {bcqtValues}\n",
    "                  \\\"\n",
    "                  efi.dcqt_values=\\\"  {dcqtValues}\n",
    "                  \\\"\n",
    "                  efi.query_terms_length={len(queryTokens)}\n",
    "                  efi.ttf_values=\\\"  {ttfValues}\n",
    "                  \\\" \n",
    "                  efi.htf_values=\\\"  {htfValues}\n",
    "                  \\\" \n",
    "                  efi.btf_values=\\\"  {btfValues}\n",
    "                  \\\" \n",
    "                  efi.dtf_values=\\\"  {dtfValues}\n",
    "                  \\\" \n",
    "                  efi.tidf_values=\\\"  {tidfValues}\n",
    "                  \\\" \n",
    "                  efi.hidf_values=\\\"  {hidfValues}\n",
    "                  \\\" \n",
    "                  efi.bidf_values=\\\"  {bidfValues}\n",
    "                  \\\" \n",
    "                  efi.didf_values=\\\"  {didfValues}\n",
    "                  \\\" \n",
    "                  efi.ttfidf_values=\\\"  {ttfidfValues}\n",
    "                  \\\" \n",
    "                  efi.htfidf_values=\\\"  {htfidfValues}\n",
    "                  \\\" \n",
    "                  efi.btfidf_values=\\\"  {btfidfValues}\n",
    "                  \\\" \n",
    "                  efi.dtfidf_values=\\\"  {dtfidfValues}\n",
    "                  \\\" \n",
    "          \"\"\"\n",
    "                +\"model=thesis-svm }\",\n",
    "                \"qf\": \"title headings body\",\n",
    "                \"defType\": \"dismax\",\n",
    "                \"q\": query\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if key == ' 10000':\n",
    "            print(json.dumps(request, indent=2))\n",
    "        \n",
    "        response = requests.post(f'http://localhost:8983/solr/thesis-ltr/select', json=request)\n",
    "        \n",
    "        topDocumentCount = 100\n",
    "        queryResult = [doc['id'] for doc in response.json()[\"response\"][\"docs\"]][:topDocumentCount]\n",
    "        \n",
    "        \n",
    "        # calculate metrics\n",
    "        # Reciprocal Rank\n",
    "        rr = reciprocalRank(key, queryResult)\n",
    "        evaluationMap[key]['rr'] = rr\n",
    "        print(f'RR: {rr}')\n",
    "        # Normalized Discounted Cumulative Gains (NDCG)\n",
    "        ndcg = normalizedDiscountedCumulativeGain(key, queryResult[:10])\n",
    "        evaluationMap[key]['ndcg'] = ndcg\n",
    "        print(f'NDCG: {ndcg}')\n",
    "        # Normalized Cumulative Gains (NCG)\n",
    "        ncg = normalizedCumulativeGain(key, queryResult)\n",
    "        evaluationMap[key]['ncg'] = ncg\n",
    "        print(f'NCG: {ncg}')\n",
    "        # Average Precision (AP)\n",
    "        ap = averagePrecision(key, queryResult)\n",
    "        evaluationMap[key]['ap'] = ap\n",
    "        print(f'AP: {ap}')\n",
    "        \n",
    "        print(f'processed {i}/{len(list(evaluationMap.keys())[:])} {key} query: {query}')\n",
    "    except KeyError as err:\n",
    "        # ignore the queries that are not in the validation queries list\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rr = 0\n",
    "bm25_ap = 0\n",
    "bm25_ndcg = 0\n",
    "bm25_ncg = 0\n",
    "counter = 0\n",
    "for key in list(evaluationMap.keys()):\n",
    "    try:\n",
    "        bm25_rr += evaluationMap[key]['rr']\n",
    "        bm25_ap += evaluationMap[key]['ap']\n",
    "        bm25_ndcg += evaluationMap[key]['ndcg']\n",
    "        bm25_ncg += evaluationMap[key]['ncg']\n",
    "        counter += 1\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rr = bm25_rr/counter\n",
    "bm25_ap = bm25_ap/counter\n",
    "bm25_ndcg = bm25_ndcg/counter\n",
    "bm25_ncg = bm25_ncg/counter\n",
    "\n",
    "print(f'exp_bm25: rr:{bm25_rr} / ap:{bm25_ap} / ndcg@10:{bm25_ndcg} / ncg:{bm25_ncg}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
